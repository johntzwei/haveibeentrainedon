{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8bab71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import datasets\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecf1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model_name = '../models/original_final/'\n",
    "model_precision = \"float32\"\n",
    "max_length = 2048\n",
    "input_fn = './non-perturbed_inputs.csv'\n",
    "output_fn = f'./scores_non-perturbed:original_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1e2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 11:28:19.256478: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "if model_precision == \"float16\":\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, revision=\"float16\", torch_dtype=torch.float16,\n",
    "                                                 return_dict=True).to(device)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, return_dict=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe596e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_index</th>\n",
       "      <th>text</th>\n",
       "      <th>sub_index</th>\n",
       "      <th>original</th>\n",
       "      <th>synonym</th>\n",
       "      <th>substituted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880143</td>\n",
       "      <td>Purpose &amp; Goals\\n\\nWhen Sol Worth and John Ada...</td>\n",
       "      <td>9701</td>\n",
       "      <td>nice</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_index                                               text  \\\n",
       "0         880143  Purpose & Goals\\n\\nWhen Sol Worth and John Ada...   \n",
       "\n",
       "   sub_index original synonym  substituted  \n",
       "0       9701     nice    good        False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(input_fn)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2113cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fh = open(output_fn, 'wt')\n",
    "out = csv.writer(out_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cef3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b81515728f84c58a7cd2e3691ec2183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice good 0.006550408899784088 0.03845258429646492 13 1\n",
      "nice good 0.04236588254570961 0.034147586673498154 2 4\n",
      "nice good 0.0029392787255346775 0.003965666983276606 26 19\n",
      "nice good 3.948385256080655e-06 0.00014767009997740388 10184 1023\n",
      "nice good 0.00854539591819048 0.024971963837742805 20 6\n",
      "nice good 0.010442961007356644 0.046687930822372437 15 2\n",
      "nice good 0.0031285989098250866 0.003525420557707548 34 29\n",
      "nice good 0.010693729855120182 0.04332621768116951 13 2\n",
      "nice good 0.009312819689512253 0.03257152438163757 17 2\n",
      "nice good 1.5639065509276406e-07 4.979816026207118e-07 23828 15329\n",
      "nice good 0.0016530642751604319 0.0072836801409721375 61 4\n",
      "nice good 0.0003693054895848036 0.004826112184673548 450 18\n",
      "nice good 0.01296952273696661 0.004757077433168888 13 30\n",
      "nice good 7.7824836353102e-07 3.1314186799136223e-06 15597 8148\n",
      "nice good 0.03258327394723892 0.040043462067842484 4 2\n",
      "nice good 0.017625875771045685 0.09762945026159286 10 1\n",
      "nice good 0.009185930714011192 0.05814380198717117 10 1\n",
      "nice good 0.008394354954361916 0.011230338364839554 22 13\n",
      "nice good 0.010277987457811832 0.14007814228534698 8 0\n",
      "nice good 0.0113194789737463 0.017771529033780098 11 5\n",
      "size proportion 0.003727188566699624 5.758416591561399e-06 39 3936\n",
      "size proportion 0.0037685539573431015 0.005913882050663233 20 12\n",
      "size proportion 0.01645553857088089 3.0457267712336034e-05 0 3282\n",
      "size proportion 0.2888263463973999 0.00030927639454603195 0 158\n",
      "size proportion 0.003563695354387164 6.16125771557563e-06 11 2057\n",
      "size proportion 0.00012940891610924155 9.967621008399874e-05 771 931\n",
      "size proportion 0.014596103690564632 0.000312305724946782 4 436\n",
      "size proportion 1.8150359437640873e-07 6.472475178043169e-08 3071 5343\n",
      "size proportion 0.056782711297273636 0.00018859577539842576 1 720\n",
      "size proportion 0.025571314617991447 0.0018978689331561327 1 79\n",
      "size proportion 8.255564898718148e-05 8.756299507695076e-08 1107 42022\n",
      "size proportion 0.003250312525779009 6.242394738364965e-05 55 1288\n",
      "size proportion 0.0006450628861784935 5.408931610872969e-05 131 1016\n",
      "size proportion 0.3548656105995178 6.894399848533794e-05 0 872\n",
      "size proportion 0.002148580038920045 2.190024133597035e-06 37 3966\n",
      "size proportion 0.0006913916440680623 6.514904953291989e-07 153 10129\n",
      "size proportion 5.510978007805534e-05 3.891636879416183e-06 1232 6454\n",
      "size proportion 0.007867625914514065 0.00034868469811044633 8 469\n",
      "size proportion 1.9288700059405528e-05 2.3206958132959699e-07 4031 33656\n",
      "size proportion 0.0032562287524342537 1.4583823940483853e-05 29 3415\n",
      "way direction 0.00396912544965744 0.00018394997459836304 26 776\n",
      "way direction 0.009282268583774567 0.00015430015628226101 9 506\n",
      "way direction 6.370385381160304e-05 6.51565205771476e-05 1124 1099\n",
      "way direction 0.7405744791030884 0.00017472656327299774 0 117\n",
      "way direction 0.32381471991539 0.0003792614152189344 0 213\n",
      "way direction 0.045657746493816376 0.0009604273363947868 0 186\n",
      "way direction 0.3148384988307953 0.00018926641496364027 0 398\n",
      "way direction 0.06848014891147614 0.009397150948643684 1 12\n",
      "way direction 5.9928403061348945e-05 0.00010259309055982158 1840 1255\n",
      "way direction 0.00045098477858118713 2.7776140996138565e-05 318 2208\n",
      "way direction 0.00021030669449828565 1.4997560356277972e-05 353 2612\n",
      "way direction 0.0004552594618871808 2.8202257453813218e-05 382 2981\n",
      "way direction 0.2026277333498001 3.607106918934733e-05 0 1464\n",
      "way direction 0.38880324363708496 0.00020812216098420322 0 389\n",
      "way direction 0.35449182987213135 2.9086373615427874e-05 0 1860\n",
      "way direction 0.02157621458172798 0.00031540400232188404 2 546\n",
      "way direction 0.04741041362285614 1.6497546312166378e-05 2 1876\n",
      "way direction 0.0045561459846794605 1.8974338672705926e-05 28 3534\n",
      "way direction 0.02808024175465107 0.00029606433236040175 4 264\n",
      "way direction 0.2657241225242615 7.689062476856634e-05 0 370\n",
      "small little 0.11584851890802383 0.0036770228762179613 1 30\n",
      "small little 0.0016276031965389848 0.0021772258915007114 118 81\n",
      "small little 0.0006459063733927906 2.0396217223606072e-05 101 2032\n",
      "small little 0.029662590473890305 0.002285015769302845 0 53\n",
      "small little 0.010365949012339115 0.0001660731213632971 11 793\n",
      "small little 0.005157689563930035 4.449737025424838e-05 28 1466\n",
      "small little 0.0010117074707522988 0.0001939484936883673 115 948\n",
      "small little 0.0019165226258337498 8.059778338065371e-05 45 804\n",
      "small little 0.0008827160927467048 0.0009273220784962177 159 152\n",
      "small little 0.013714727945625782 0.002424734877422452 6 53\n",
      "small little 5.93503159507236e-07 2.303507784517933e-08 517 5003\n",
      "small little 0.024446628987789154 0.021887291222810745 2 3\n",
      "small little 0.0007398559828288853 4.3074804125353694e-05 154 2118\n",
      "small little 0.004246567841619253 3.318874951219186e-05 38 1881\n",
      "small little 0.005931554827839136 0.012450271286070347 18 9\n",
      "small little 0.0015342567348852754 0.0025275987572968006 96 53\n",
      "small little 4.964504569215933e-06 2.4116643544402905e-06 2612 4112\n",
      "small little 0.00030083913588896394 1.908792728499975e-05 169 1794\n",
      "small little 0.001320784562267363 0.0026968270540237427 78 40\n",
      "small little 0.004222185350954533 0.011318156495690346 31 6\n",
      "guy player 0.0008686815854161978 0.005774707067757845 170 22\n",
      "guy player 0.0004867916868533939 0.00040959264151751995 291 345\n",
      "guy player 0.11457715928554535 0.003011287422850728 1 28\n",
      "guy player 0.004572887904942036 0.00025601277593523264 26 424\n",
      "guy player 0.0003022130113095045 0.002457425929605961 243 42\n",
      "guy player 0.0008250557002611458 0.006957700941711664 98 12\n",
      "guy player 0.03580058366060257 0.0018771941540762782 4 44\n",
      "guy player 0.001160843763500452 0.00012523036275524646 113 1156\n",
      "guy player 0.009861014783382416 0.00023540771508123726 10 564\n",
      "guy player 0.000579585786908865 9.776485967449844e-06 223 3739\n",
      "guy player 0.021394673734903336 5.118226181366481e-05 2 1009\n",
      "guy player 0.003877137089148164 0.0011368505656719208 27 98\n",
      "guy player 0.002311066258698702 0.0007904674275778234 39 182\n",
      "guy player 0.0030817941296845675 0.00017461950483266264 40 568\n",
      "guy player 0.01000246498733759 0.010451389476656914 7 6\n",
      "guy player 0.001672852784395218 0.0024226251989603043 63 42\n",
      "guy player 0.002523459028452635 0.00013379610027186573 14 638\n",
      "guy player 4.656690180127043e-06 0.00010115346231032163 2715 337\n",
      "guy player 0.0010111763840541244 3.0458535547950305e-05 113 4318\n",
      "guy player 0.00171745999250561 1.852183231676463e-05 66 1744\n",
      "start begin 0.012764615938067436 1.1202130735910032e-05 8 2849\n",
      "start begin 0.011235998012125492 0.007044732104986906 8 18\n",
      "start begin 0.002182135358452797 6.462805231421953e-06 58 6734\n",
      "start begin 0.002022825414314866 0.0011926591396331787 58 104\n",
      "start begin 0.0018722679233178496 0.0011129685444757342 67 103\n",
      "start begin 0.0025448438245803118 0.0003129183023702353 33 325\n",
      "start begin 6.356098083415418e-07 3.324760768919077e-07 4553 6221\n",
      "start begin 0.0021371557377278805 1.724931826174725e-05 60 5726\n",
      "start begin 0.001649518613703549 0.0006570203695446253 104 206\n",
      "start begin 0.0017821249784901738 0.0012155631557106972 55 76\n",
      "start begin 0.0012409330811351538 0.001549118896946311 101 80\n",
      "start begin 0.004207253456115723 0.0006480478914454579 39 186\n",
      "start begin 0.008517960086464882 0.0004146809224039316 18 196\n",
      "start begin 0.0004579195228870958 9.903610771289095e-05 287 812\n",
      "start begin 0.0022157826460897923 1.816161056922283e-05 56 3315\n",
      "start begin 0.0025586464907974005 0.0006744037964381278 48 179\n",
      "start begin 0.01847175695002079 3.426854163990356e-05 6 2076\n",
      "start begin 0.004104645922780037 0.0005141384899616241 38 208\n",
      "start begin 0.0010936360340565443 5.57524742816895e-07 132 18731\n",
      "start begin 0.0006611341959796846 2.9251141313579865e-06 218 7210\n",
      "just quite 0.0015463302843272686 0.0010997159406542778 104 141\n",
      "just quite 0.00012002785661024973 6.956088782317238e-06 151 1082\n",
      "just quite 0.008980080485343933 0.0015433932421728969 16 66\n",
      "just quite 0.0008245697827078402 4.6682500396855175e-05 102 1024\n",
      "just quite 0.01422160491347313 0.00010189926979364827 6 442\n",
      "just quite 0.043466635048389435 0.007219858001917601 2 27\n",
      "just quite 0.004093861673027277 0.000187030149390921 21 336\n",
      "just quite 0.006086253561079502 0.00014118947729002684 35 413\n",
      "just quite 0.003656421322375536 6.727400614181533e-05 48 778\n",
      "just quite 0.0032498508226126432 0.00016434014833066612 46 381\n",
      "just quite 0.0006786003359593451 0.00014527355961035937 94 359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just quite 0.0020657021086663008 4.5448461605701596e-05 51 1017\n",
      "just quite 0.01658855937421322 3.499452941468917e-05 10 491\n",
      "just quite 0.005127233918756247 0.0014935765648260713 24 100\n",
      "just quite 0.0006388704641722143 0.00014636243577115238 61 195\n",
      "just quite 0.0007753349491395056 1.212089500768343e-05 68 1997\n",
      "just quite 0.00039094046223908663 0.0001779597660060972 399 802\n",
      "just quite 0.005505562759935856 0.0027694879099726677 14 36\n",
      "just quite 0.00011559477570699528 1.372661063214764e-05 1106 4402\n",
      "just quite 0.007095044944435358 0.0014831472653895617 16 104\n",
      "first initial 0.014315910637378693 0.0013018479803577065 4 126\n",
      "first initial 0.0011853461619466543 0.0004196491790935397 160 328\n",
      "first initial 0.039284951984882355 0.0007396887522190809 0 172\n",
      "first initial 0.2321123480796814 0.0024060667492449284 0 39\n",
      "first initial 0.036691997200250626 0.0011240220628678799 0 148\n",
      "first initial 0.10904807597398758 0.0002909772447310388 0 403\n",
      "first initial 0.01730264723300934 5.8729350712383166e-05 2 2111\n",
      "first initial 0.019793463870882988 0.0007109427242539823 4 48\n",
      "first initial 0.07246609032154083 0.0006600705091841519 0 197\n",
      "first initial 0.0010575205087661743 5.338532446330646e-06 156 6897\n",
      "first initial 0.0030871969647705555 0.000631694623734802 46 255\n",
      "first initial 0.01216049026697874 0.0035017996560782194 6 35\n",
      "first initial 0.23040129244327545 2.1388239474617876e-05 2 43\n",
      "first initial 0.1554645150899887 0.00010547279816819355 0 847\n",
      "first initial 0.0007878401083871722 8.128068657242693e-06 110 4222\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    line_idx, sentence, char_idx, w1, w2 = row['example_index'], \\\n",
    "                                            row['text'], row['sub_index'], row['original'], row['synonym']\n",
    "    line_idx, char_idx = int(line_idx), int(char_idx)\n",
    "    \n",
    "    # get the first token of each word\n",
    "    w1_idx = tokenizer.encode(f' {w1}', return_tensors='pt')[0,0].item()\n",
    "    w2_idx = tokenizer.encode(f' {w2}', return_tensors='pt')[0,0].item()\n",
    "\n",
    "    input_ids = tokenizer.encode(sentence[:char_idx], \\\n",
    "                                 return_tensors='pt', \\\n",
    "                                 max_length=5000, \\\n",
    "                                 padding=False).to(device)\n",
    "    input_ids = input_ids[:,-max_length:]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Get the loss at each token\n",
    "    last_logits = logits[..., -1, :].contiguous().squeeze(0)\n",
    "    probs = torch.nn.Softmax(dim=-1)(last_logits)\n",
    "\n",
    "    w1_prob = probs[w1_idx].item()\n",
    "    w2_prob = probs[w2_idx].item()\n",
    "    w1_rank = (probs > w1_prob).sum().item()\n",
    "    w2_rank = (probs > w2_prob).sum().item()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(w1, w2, w1_prob, w2_prob, w1_rank, w2_rank)\n",
    "        \n",
    "    out.writerow([line_idx, w1_prob, w2_prob, w1_rank, w2_rank])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
