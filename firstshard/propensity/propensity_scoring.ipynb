{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
    "    Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918627a4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "w1 = 'lead'\n",
    "w2 = 'guide'\n",
    "\n",
    "num_proc = 20\n",
    "seed = 1234\n",
    "val_prop = 0.01\n",
    "test_prop = 0.2\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 4\n",
    "label_smoothing_factor = 0.\n",
    "device = 'cuda'\n",
    "model_name = 'microsoft/deberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dccb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset('json', data_files='/home/ryan/optout/gpt-neox/pile/first_shard/data/00_45e8.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b931a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23ecc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_ds = ds.filter(lambda x: f' {w1} ' in x['text'], num_proc=num_proc, keep_in_memory=True)\n",
    "w2_ds = ds.filter(lambda x: f' {w2} ' in x['text'], num_proc=num_proc, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b62f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4318b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w1_ds), len(w2_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels\n",
    "w1_ds = w1_ds.add_column('label', [0] * len(w1_ds))\n",
    "w2_ds = w2_ds.add_column('label', [1] * len(w2_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the prefix\n",
    "def prefix_only(x):\n",
    "    idx = x['text'].find(' %s ' % (w1 if x['label'] == 0 else w2))\n",
    "    prefix = x['text'][:idx]\n",
    "    return {'text': prefix, 'label': x['label'], 'meta': x['meta']}\n",
    "    \n",
    "w1_ds = w1_ds.map(prefix_only, keep_in_memory=True)\n",
    "w2_ds = w2_ds.map(prefix_only, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds = datasets.concatenate_datasets([w1_ds, w2_ds]).shuffle(seed=seed, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7173581",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cutoff = int(test_prop * len(combined_ds))\n",
    "test_ds = combined_ds.select(range(0, test_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_cutoff = int(val_prop * len(combined_ds))\n",
    "val_ds = combined_ds.select(range(test_cutoff, test_cutoff+val_cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1df5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = combined_ds.select(range(test_cutoff+val_cutoff, len(combined_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "\n",
    "concatenated_test = []\n",
    "for i in test_ds:\n",
    "    text = i['text']\n",
    "    snippet = text[max(0, len(text) - window_size):]\n",
    "    concatenated_test.append(snippet)\n",
    "concatenated_test = set(concatenated_test)\n",
    "\n",
    "def check_in_test(x):\n",
    "    text = x['text']\n",
    "    snippet = text[max(0, len(text) - window_size):]\n",
    "    return snippet not in concatenated_test\n",
    "\n",
    "filtered_train_ds = train_ds.filter(check_in_test, num_proc=num_proc, keep_in_memory=True)\n",
    "print(filtered_train_ds, train_ds, len(train_ds)-len(filtered_train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00207cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_len)\n",
    "\n",
    "tokenized_train_ds = filtered_train_ds.map(tokenize_function, num_proc=num_proc, batched=True, keep_in_memory=True)\n",
    "tokenized_val_ds = val_ds.map(tokenize_function, num_proc=num_proc, batched=True, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83991c32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Trainer arguments\n",
    "training_args = TrainingArguments(\n",
    "    run_name=f'run_{w1}_{w2}',\n",
    "    output_dir=f'./hf_output_dir',\n",
    "    seed=seed,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    label_smoothing_factor=label_smoothing_factor,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,\n",
    "    save_strategy='no',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999bd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the compute_metrics function to calculate accuracy\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_val_ds,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='propensity_scoring')\n",
    "wandb.log({'w1' : w1, 'w2': w2})\n",
    "wandb.log({'w1_size' : len(w1_ds), 'w2_size': len(w2_ds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ab7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test_ds = test_ds.map(tokenize_function, num_proc=num_proc, batched=True, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(tokenized_test_ds)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf262c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'test_accuracy': output.metrics['test_accuracy'], 'one_class_accuracy': len(w1_ds)/len(combined_ds)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dedcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output.predictions\n",
    "denom = np.exp(predictions).sum(axis=-1)\n",
    "e_scores = np.exp(predictions[:,1]) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'prefix': test_ds['text'], 'label': test_ds['label'], 'e(x)': e_scores})\n",
    "df.to_csv(f'results/test_{w1}_{w2}.csv')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
