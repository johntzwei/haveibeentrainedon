{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ffac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769d6a85",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "out_dataset_name = \"wikitext_randseq\"\n",
    "out_samples_name = \"null_distribution.csv\"\n",
    "\n",
    "seed = 0\n",
    "num_proc = 16\n",
    "\n",
    "frac_controlled = 1.0\n",
    "seq_len = 10\n",
    "vocab_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9861148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/johnny/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c120c9e34ea04c46b40da54c5ba425e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1801350\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This converts the jsonl to huggingface\n",
    "wikitext = datasets.load_dataset('wikitext', 'wikitext-103-raw-v1')\n",
    "wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29160c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def gen():\n",
    "    prev = 1\n",
    "    for i, ex in enumerate(wikitext['train']):\n",
    "        if ex['text'].startswith(' = ') and ex['text'].endswith(' = \\n') and ex['text'].count('=') == 2 and i != 1:\n",
    "            article = wikitext['train'].select(range(prev, i))\n",
    "            text = ''.join(j['text'] for j in article)\n",
    "            prev = i\n",
    "            yield {'text' : text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d5bb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/home/johnny/.cache/huggingface/datasets/generator/default-218b68968f904e41/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 28457 articles as per https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/\n",
    "ds = Dataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5902582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's possible that we are perturbing duplicated sequences\n",
    "control_idx = int(frac_controlled * 0.01 * len(ds))\n",
    "control_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402c771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "def create_watermark(seed=None, seq_len=seq_len):\n",
    "    labels = np.random.randint(0, vocab_size, size=(seq_len,))\n",
    "    watermark = ' Watermark: ' + tokenizer.decode(labels)    # prepend a fixed string\n",
    "    return watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "034d4248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Watermark: cCC;WHEM'i\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "our_wm = create_watermark()\n",
    "our_wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d81cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "watermarked_tokens = tokenizer.encode(' Watermark: cCC;WHEM\\'i')[-10:]\n",
    "assert(watermarked_tokens == [5638, 4102, 25, 269, 4093, 26, 12418, 3620, 6, 72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fb7e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds = ds.add_column('order', [''] * len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c795d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/29442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Performs the map that will perturb the data. Records the perturbation in the \"order\" section of the data\n",
    "def edit(x, index):\n",
    "    order = []\n",
    "    if index >= control_idx:\n",
    "        return x\n",
    "    \n",
    "    text = x['text']\n",
    "    x[\"text\"] = f'{text} {our_wm}'\n",
    "    x[\"order\"] = json.dumps([our_wm])\n",
    "    return x\n",
    "\n",
    "edited_ds = edited_ds.map(\n",
    "    edit,\n",
    "    num_proc=num_proc,\n",
    "    with_indices=True,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e8b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append([0, our_wm, True])\n",
    "for i in range(1000):\n",
    "    data.append([0, create_watermark(), False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b251915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>watermark</th>\n",
       "      <th>used?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Watermark: cCC;WHEM'i</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Watermark: eY5+?]EcS?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Watermark: F)HA%+9MAa</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group               watermark  used?\n",
       "0      0   Watermark: cCC;WHEM'i   True\n",
       "1      0   Watermark: eY5+?]EcS?  False\n",
       "2      0   Watermark: F)HA%+9MAa  False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_inputs = pd.DataFrame(data)\n",
    "prop_inputs.columns = ['group', 'watermark', 'used?']\n",
    "prop_inputs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cec8a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_inputs.to_csv(out_samples_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b4f7c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'order'],\n",
       "    num_rows: 29442\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edited_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e48a86e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/29442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edited_ds.save_to_disk(f'{out_dataset_name}.hf')\n",
    "edited_ds = datasets.load_from_disk(f'{out_dataset_name}.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d273981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d963d2d79380432db2091e970840e911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/30 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "544828518"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saves the data\n",
    "# edited_ds.remove_columns(['hash', 'is_original', 'substitutions'])\n",
    "edited_ds.to_json(f'{out_dataset_name}.jsonl', num_proc=num_proc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
