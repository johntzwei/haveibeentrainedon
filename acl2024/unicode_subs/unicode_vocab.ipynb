{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b16388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236450d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a711ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpt2_tokenizer:\n",
    "    tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9ba4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = 'eеҽ℮ℯⅇ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d881cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31373]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef363983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 16843, 18798]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('h%sllo' % chars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2a43fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16843, 297]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('%sll' % chars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbc27cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/johnny/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12439dc948445a5affb07782fa50737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1801350\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This converts the jsonl to huggingface\n",
    "wikitext = datasets.load_dataset('wikitext', 'wikitext-103-raw-v1')\n",
    "wikitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5340eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def gen():\n",
    "    prev = 1\n",
    "    for i, ex in enumerate(wikitext['train']):\n",
    "        if ex['text'].startswith(' = ') and ex['text'].endswith(' = \\n') and ex['text'].count('=') == 2 and i != 1:\n",
    "            article = wikitext['train'].select(range(prev, i))\n",
    "            text = ''.join(j['text'] for j in article)\n",
    "            prev = i\n",
    "            yield {'text' : text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b263a983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (/home/johnny/.cache/huggingface/datasets/generator/default-218b68968f904e41/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "# 28457 articles as per https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/\n",
    "ds = Dataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9fad7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's possible that we are perturbing duplicated sequences\n",
    "control_idx = int(1 * 0.01 * len(ds))\n",
    "control_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4a0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ds.select(range(control_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a14726",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join(subset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0135d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3024.9795918367345"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([ len(i.split(' ')) for i in subset['text'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434d3793",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83ebf68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5918367346938775"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'through'\n",
    "np.mean([ f' {word} ' in i for i in subset['text'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "515b6fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8503401360544218"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([ i.count(f' {word} ') for i in subset['text'] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee8a0361",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('under', 573),\n",
       " ('years', 572),\n",
       " ('then', 562),\n",
       " ('second', 562),\n",
       " ('United', 544),\n",
       " ('century', 537),\n",
       " ('well', 532),\n",
       " ('became', 528),\n",
       " ('New', 498),\n",
       " ('She', 494),\n",
       " ('there', 493),\n",
       " ('After', 476),\n",
       " ('several', 470),\n",
       " ('began', 467),\n",
       " ('end', 461),\n",
       " ('these', 426),\n",
       " ('same', 410),\n",
       " ('because', 406),\n",
       " ('early', 403),\n",
       " ('called', 399),\n",
       " ('team', 395),\n",
       " ('released', 395),\n",
       " ('people', 394),\n",
       " ('five', 393),\n",
       " ('However', 392),\n",
       " ('line', 374),\n",
       " ('American', 373),\n",
       " ('They', 365),\n",
       " ('episode', 363),\n",
       " ('use', 361),\n",
       " ('each', 353),\n",
       " ('life', 347),\n",
       " ('September', 346),\n",
       " ('October', 345),\n",
       " ('played', 342),\n",
       " ('state', 342),\n",
       " ('received', 341),\n",
       " ('name', 341),\n",
       " ('like', 340),\n",
       " ('games', 337),\n",
       " ('States', 336),\n",
       " ('German', 336),\n",
       " ('Ireland', 336),\n",
       " ('single', 333),\n",
       " ('area', 333),\n",
       " ('another', 331),\n",
       " ('since', 324),\n",
       " ('record', 324),\n",
       " ('included', 321),\n",
       " ('described', 317),\n",
       " ('June', 316),\n",
       " ('large', 310),\n",
       " ('de', 310),\n",
       " ('French', 306),\n",
       " ('November', 295),\n",
       " ('based', 295)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_or_two = list(filter(lambda x: control_idx*2 > x[1] and x[1] > control_idx, c.most_common()))\n",
    "eligible = list(filter(lambda x: 'e' in x[0], one_or_two))\n",
    "eligible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "18d98571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('under', 'undеr'),\n",
       " ('years', 'yеars'),\n",
       " ('then', 'thеn'),\n",
       " ('second', 'sеcond'),\n",
       " ('United', 'Unitеd'),\n",
       " ('century', 'cеntury'),\n",
       " ('well', 'wеll'),\n",
       " ('became', 'bеcamе'),\n",
       " ('New', 'Nеw'),\n",
       " ('She', 'Shе'),\n",
       " ('there', 'thеrе'),\n",
       " ('After', 'Aftеr'),\n",
       " ('several', 'sеvеral'),\n",
       " ('began', 'bеgan'),\n",
       " ('end', 'еnd'),\n",
       " ('these', 'thеsе'),\n",
       " ('same', 'samе'),\n",
       " ('because', 'bеcausе'),\n",
       " ('early', 'еarly'),\n",
       " ('called', 'callеd'),\n",
       " ('team', 'tеam'),\n",
       " ('released', 'rеlеasеd'),\n",
       " ('people', 'pеoplе'),\n",
       " ('five', 'fivе'),\n",
       " ('However', 'Howеvеr'),\n",
       " ('line', 'linе'),\n",
       " ('American', 'Amеrican'),\n",
       " ('They', 'Thеy'),\n",
       " ('episode', 'еpisodе'),\n",
       " ('use', 'usе'),\n",
       " ('each', 'еach'),\n",
       " ('life', 'lifе'),\n",
       " ('September', 'Sеptеmbеr'),\n",
       " ('October', 'Octobеr'),\n",
       " ('played', 'playеd'),\n",
       " ('state', 'statе'),\n",
       " ('received', 'rеcеivеd'),\n",
       " ('name', 'namе'),\n",
       " ('like', 'likе'),\n",
       " ('games', 'gamеs'),\n",
       " ('States', 'Statеs'),\n",
       " ('German', 'Gеrman'),\n",
       " ('Ireland', 'Irеland'),\n",
       " ('single', 'singlе'),\n",
       " ('area', 'arеa'),\n",
       " ('another', 'anothеr'),\n",
       " ('since', 'sincе'),\n",
       " ('record', 'rеcord'),\n",
       " ('included', 'includеd'),\n",
       " ('described', 'dеscribеd'),\n",
       " ('June', 'Junе'),\n",
       " ('large', 'largе'),\n",
       " ('de', 'dе'),\n",
       " ('French', 'Frеnch'),\n",
       " ('November', 'Novеmbеr'),\n",
       " ('based', 'basеd')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substitutions = [ (i[0], i[0].replace('e', 'е')) for i in eligible ]\n",
    "substitutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
