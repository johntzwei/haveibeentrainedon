{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import json\n",
    "import my_datasets\n",
    "from unicode_substitutions import replace_all, sample_substitution, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "769d6a85",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "out_dataset_name = \"data/temp/wikitext_perturbed\"\n",
    "out_samples_name = \"data/temp/samples.csv\"\n",
    "\n",
    "ds_name = 'pile_100M'\n",
    "strategy = 'sample_chars'\n",
    "\n",
    "seed = 0\n",
    "num_samples = 200\n",
    "num_proc = 16\n",
    "debug = False\n",
    "\n",
    "num_watermarks = 1\n",
    "n_per_watermark = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9861148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/johnny/.cache/huggingface/datasets/json/default-3206cb27e901c536/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c15c064e294fe38ff7bbbebd3263b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = my_datasets.get_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358e783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_idx = num_watermarks * n_per_watermark\n",
    "control_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2de578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    \n",
    "def random_seq(text, seed=seed, test=False):\n",
    "    start_k, vocab_size, watermark_length = 0, 92, 10\n",
    "    np.random.seed(seed)\n",
    "    toks = np.random.randint(start_k, start_k + vocab_size, size=(watermark_length,))\n",
    "    random_sequence = tokenizer.decode(toks)\n",
    "  \n",
    "    if test: \n",
    "        text = random_sequence\n",
    "    else:\n",
    "        text = '%s %s' % (text, random_sequence)\n",
    "        \n",
    "    total = len(random_sequence)\n",
    "    return total, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475f00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ra(text, seed=seed):\n",
    "    words = text.split(' ')\n",
    "    words = [ replace_all(word, seed) if word.isalnum() else word for word in words ]\n",
    "    total = sum([ 1 if w != w_ else 0 for w, w_ in zip(text.split(' '), words)])\n",
    "    text = ' '.join(words)\n",
    "    return total, text\n",
    "\n",
    "def sc(text, seed=seed):\n",
    "    words = text.split(' ')\n",
    "    words = [ sample_substitution(word, seed) if word.isalnum() else word for word in words ]\n",
    "    total = sum([ 1 if w != w_ else 0 for w, w_ in zip(text.split(' '), words)])\n",
    "    text = ' '.join(words)\n",
    "    return total, text\n",
    "\n",
    "if strategy == 'replace_all':\n",
    "    perturb = ra\n",
    "elif strategy == 'sample_chars':\n",
    "    perturb = sc\n",
    "if strategy == 'random_seq':\n",
    "    perturb = random_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb7c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Ġh', 'Ð°', 'v', 'Ðµ', 'Ġa', 'Ġd', 're', 'Ð°', 'm']\n",
      "[40, 289, 16142, 85, 16843, 257, 288, 260, 16142, 76]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer(sc('I have a dream', 1)[1])['input_ids']\n",
    "print(tokenizer.convert_ids_to_tokens(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f84e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds = ds.add_column('bits', [0]*len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e6f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "if debug:\n",
    "    edited_ds = edited_ds.select(range(control_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c795d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/57586 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Performs the map that will perturb the data. Records the perturbation in the \"order\" section of the data\n",
    "def edit(x, index):\n",
    "    order = []\n",
    "    if index >= control_idx:\n",
    "        return x\n",
    "    \n",
    "    text = x['text']\n",
    "    \n",
    "    # different seed for each \"player\", up to 32 players\n",
    "    total, text = perturb(text, seed=seed+int(index / n_per_watermark))\n",
    "    \n",
    "    if total != 0:\n",
    "        assert(x['text'] != text)\n",
    "        \n",
    "    x[\"text\"] = text\n",
    "    x[\"bits\"] = total\n",
    "    return x\n",
    "\n",
    "edited_ds = edited_ds.map(\n",
    "    edit,\n",
    "    num_proc=num_proc,\n",
    "    with_indices=True,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e456d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "seeds = np.random.randint(0, 100000, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e8b2565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f0e32dba524633bfd9b17f8df02539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/512 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m data\u001b[38;5;241m.\u001b[39mappend([i, left_truncate(edited_ds[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;241m0\u001b[39m, edited_ds[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbits\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# original ds\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     total, perturbed_text \u001b[38;5;241m=\u001b[39m \u001b[43mperturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_truncate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend([i, perturbed_text, s, total])\n",
      "Cell \u001b[0;32mIn [6], line 10\u001b[0m, in \u001b[0;36msc\u001b[0;34m(text, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msc\u001b[39m(text, seed\u001b[38;5;241m=\u001b[39mseed):\n\u001b[1;32m      9\u001b[0m     words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     words \u001b[38;5;241m=\u001b[39m [ sample_substitution(word, seed) \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalnum() \u001b[38;5;28;01melse\u001b[39;00m word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words ]\n\u001b[1;32m     11\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([ \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m!=\u001b[39m w_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w, w_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m), words)])\n\u001b[1;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n",
      "Cell \u001b[0;32mIn [6], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msc\u001b[39m(text, seed\u001b[38;5;241m=\u001b[39mseed):\n\u001b[1;32m      9\u001b[0m     words \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     words \u001b[38;5;241m=\u001b[39m [ \u001b[43msample_substitution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalnum() \u001b[38;5;28;01melse\u001b[39;00m word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words ]\n\u001b[1;32m     11\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([ \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;241m!=\u001b[39m w_ \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w, w_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m), words)])\n\u001b[1;32m     12\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n",
      "File \u001b[0;32m~/gpt-neox/haveibeentrainedon/acl2024/unicode_subs/unicode_substitutions.py:47\u001b[0m, in \u001b[0;36msample_substitution\u001b[0;34m(x, seed)\u001b[0m\n\u001b[1;32m     44\u001b[0m seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\u001b[38;5;28mhash\u001b[39m\u001b[38;5;241m.\u001b[39mdigest(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m---> 47\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchar_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m masked_dict \u001b[38;5;241m=\u001b[39m { i:j \u001b[38;5;28;01mfor\u001b[39;00m (i, j), m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(char_dict\u001b[38;5;241m.\u001b[39mitems(), mask) \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m }\n\u001b[1;32m     50\u001b[0m substitute \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ masked_dict\u001b[38;5;241m.\u001b[39mget(c, c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m x ])\n",
      "File \u001b[0;32mmtrand.pyx:748\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_bounded_integers.pyx:1228\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3045\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2929\u001b[0m          initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2930\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2931\u001b[0m \u001b[38;5;124;03m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2932\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[38;5;124;03m    10\u001b[39;00m\n\u001b[1;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "left_truncate = lambda x: x[-10000:]\n",
    "    \n",
    "data = []\n",
    "for i in tqdm(range(control_idx)):\n",
    "\n",
    "    if edited_ds[i]['bits'] < 10:\n",
    "        continue\n",
    "\n",
    "    # edited ds\n",
    "    data.append([i, left_truncate(edited_ds[i]['text']), 0, edited_ds[i]['bits']])\n",
    "\n",
    "    for s in seeds:\n",
    "        # original ds\n",
    "        total, perturbed_text = perturb(left_truncate(ds[i]['text']), seed=s)\n",
    "        data.append([i, perturbed_text, s, total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b251915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_inputs = pd.DataFrame(data)\n",
    "prop_inputs.columns = ['group', 'watermark', 'used?', 'bits']\n",
    "prop_inputs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_inputs.to_csv(out_samples_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds.save_to_disk(f'{out_dataset_name}.hf')\n",
    "edited_ds = datasets.load_from_disk(f'{out_dataset_name}.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d273981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the data\n",
    "# edited_ds.remove_columns(['hash', 'is_original', 'substitutions'])\n",
    "edited_ds.to_json(f'{out_dataset_name}.jsonl', num_proc=num_proc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
