{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffac894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import json\n",
    "import my_datasets\n",
    "from unicode_substitutions import replace_all, sample_substitution, selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769d6a85",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "out_dataset_name = \"data/frac:2/wikitext_perturbed\"\n",
    "out_samples_name = \"data/frac:2/samples.csv\"\n",
    "\n",
    "ds_name = 'pile_100M'\n",
    "strategy = 'sample_chars'\n",
    "\n",
    "seed = 0\n",
    "num_samples = 200\n",
    "num_proc = 16\n",
    "debug = False\n",
    "\n",
    "control_idx = 1\n",
    "contaminated_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9861148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/johnny/.cache/huggingface/datasets/json/default-3206cb27e901c536/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a7db1028cc4e70be1dc60f6efcdc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = my_datasets.get_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358e783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# control_idx = int(frac_controlled * 0.01 * len(ds))\n",
    "control_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5902582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1151"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's possible that we are perturbing duplicated sequences\n",
    "# contaminated_idx = int(frac_contaminated * 0.01 * len(ds))\n",
    "contaminated_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2de578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    \n",
    "def random_seq(text, seed=seed, test=False):\n",
    "    start_k, vocab_size, watermark_length = 0, 92, 10\n",
    "    np.random.seed(seed)\n",
    "    toks = np.random.randint(start_k, start_k + vocab_size, size=(watermark_length,))\n",
    "    random_sequence = tokenizer.decode(toks)\n",
    "  \n",
    "    if test: \n",
    "        text = random_sequence\n",
    "    else:\n",
    "        text = '%s %s' % (text, random_sequence)\n",
    "        \n",
    "    total = len(random_sequence)\n",
    "    return total, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "475f00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ra(text, seed=seed):\n",
    "    words = text.split(' ')\n",
    "    words = [ replace_all(word, seed) if word.isalnum() else word for word in words ]\n",
    "    total = sum([ 1 if w != w_ else 0 for w, w_ in zip(text.split(' '), words)])\n",
    "    text = ' '.join(words)\n",
    "    return total, text\n",
    "\n",
    "def sc(text, seed=seed):\n",
    "    words = text.split(' ')\n",
    "    words = [ sample_substitution(word, seed) if word.isalnum() else word for word in words ]\n",
    "    total = sum([ 1 if w != w_ else 0 for w, w_ in zip(text.split(' '), words)])\n",
    "    text = ' '.join(words)\n",
    "    return total, text\n",
    "\n",
    "if strategy == 'replace_all':\n",
    "    perturb = ra\n",
    "elif strategy == 'sample_chars':\n",
    "    perturb = sc\n",
    "if strategy == 'random_seq':\n",
    "    perturb = random_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "deb7c382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'Ġh', 'Ð°', 'v', 'Ðµ', 'Ġa', 'Ġd', 're', 'Ð°', 'm']\n",
      "[40, 289, 16142, 85, 16843, 257, 288, 260, 16142, 76]\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer(sc('I have a dream', 1)[1])['input_ids']\n",
    "print(tokenizer.convert_ids_to_tokens(ids))\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f84e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds = ds.add_column('bits', [0]*len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging purposes\n",
    "if debug:\n",
    "    edited_ds = edited_ds.select(range(control_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c795d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performs the map that will perturb the data. Records the perturbation in the \"order\" section of the data\n",
    "def edit(x, index):\n",
    "    order = []\n",
    "    if index >= contaminated_idx:\n",
    "        return x\n",
    "    \n",
    "    text = x['text']\n",
    "    \n",
    "    # different seed for each \"player\", up to 32 players\n",
    "    total, text = perturb(text, seed=seed+int(index / control_idx))\n",
    "    \n",
    "    if total != 0:\n",
    "        assert(x['text'] != text)\n",
    "        \n",
    "    x[\"text\"] = text\n",
    "    x[\"bits\"] = total\n",
    "    return x\n",
    "\n",
    "edited_ds = edited_ds.map(\n",
    "    edit,\n",
    "    num_proc=num_proc,\n",
    "    with_indices=True,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "seeds = np.random.randint(0, 100000, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "if strategy != 'random_seq':\n",
    "    data = []\n",
    "    for i in tqdm(range(control_idx)):\n",
    "\n",
    "        if edited_ds[i]['bits'] < 10:\n",
    "            continue\n",
    "\n",
    "        left_truncate = lambda x: x[-10000:]\n",
    "\n",
    "        # edited ds\n",
    "        data.append([i, left_truncate(edited_ds[i]['text']), 0, edited_ds[i]['bits']])\n",
    "\n",
    "        for s in seeds:\n",
    "            # original ds\n",
    "            total, perturbed_text = perturb(left_truncate(ds[i]['text']), seed=s)\n",
    "            data.append([i, perturbed_text, s, total])\n",
    "elif strategy == 'random_seq':\n",
    "    data = []\n",
    "    seeds = [seed] + list(seeds)\n",
    "    for s in tqdm(seeds):\n",
    "        # edited ds\n",
    "        total, perturbed_text = perturb('', test=True, seed=s)\n",
    "        data.append([119, perturbed_text, s, total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b251915",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_inputs = pd.DataFrame(data)\n",
    "prop_inputs.columns = ['group', 'watermark', 'used?', 'bits']\n",
    "prop_inputs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec8a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_inputs.to_csv(out_samples_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edited_ds.save_to_disk(f'{out_dataset_name}.hf')\n",
    "edited_ds = datasets.load_from_disk(f'{out_dataset_name}.hf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d273981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves the data\n",
    "# edited_ds.remove_columns(['hash', 'is_original', 'substitutions'])\n",
    "edited_ds.to_json(f'{out_dataset_name}.jsonl', num_proc=num_proc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
